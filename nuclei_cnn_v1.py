# -*- coding: utf-8 -*-
"""Nuclei_CNN_V1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11R7VLp8rgbMmPo7XrD_XMKAWn-sydnZh

This Notebook is prepared by Dara Rouholiman as part of his Udacity Machine Learning Nanodegree Capstone Project. 

Table of Contents: 

 I. Libraries installation and imports
 
 II. clone/download the data sets
 
1.   Intrduction & Problem Statement 
2.   GPU capacity calculations (revised for google colab)
3.   Data Exploration 
4.   Data Pre-processing 
5.   Unet model Implementation 
6.   Results 
7.   link to Benchmark
"""

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
  process = psutil.Process(os.getpid())
  print('Gen RAM Free: ' + humanize.naturalsize( psutil.virtual_memory().available ), ' I Proc size: ' + humanize.naturalsize( process.memory_info().rss))
  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

#Import necessary modules and set global constants and variables. 
# https://keras.io/
!pip install -q keras
# https://opencv.org/
!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python
!pip install tqdm
import cv2
import tensorflow as tf            
import pandas as pd                 
import numpy as np                                       
import sklearn.model_selection     # For using KFold
import keras.preprocessing.image   # For using image generation
import datetime                    # To measure running time 
import skimage.transform           # For resizing images
import skimage.morphology          # For using image labeling
import cv2                         # To read and manipulate images
import os                          # For filepath, directory handling
import sys                         # System-specific parameters and functions
#import tqdm                        # Use smart progress meter
#import seaborn as sns              # For pairplots
import matplotlib.pyplot as plt    # Python 2D plotting library
import matplotlib.cm as cm         # Color map
# %matplotlib inline
from subprocess import check_output
import random
import skimage.io
import shutil
from subprocess import check_output
from skimage import transform
import random 
from keras.utils import Progbar

from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose,Convolution2D
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras import backend as K
from tqdm import tqdm

!git clone --recursive https://github.com/darar1/datasciencebowl2018.git
!ls
# Data Path
TRAIN_PATH = 'datasciencebowl2018/stage1_training/'
TEST_PATH = 'datasciencebowl2018/stage1_testing/'

print(check_output(["ls", "datasciencebowl2018/"]).decode("utf8"))

def read_image_labels(image_id):
    # most of the content in this function is taken from 'Example Metric Implementation' kernel 
    # by 'William Cukierski'
    image_file = "datasciencebowl2018/stage1_training/{}/images/{}.png".format(image_id,image_id)
    mask_file = "datasciencebowl2018/stage1_training/{}/masks/*.png".format(image_id)
    image = skimage.io.imread(image_file)
    masks = skimage.io.imread_collection(mask_file).concatenate()    
    height, width, _ = image.shape
    num_masks = masks.shape[0]
    labels = np.zeros((height, width), np.uint16)
    for index in range(0, num_masks):
        labels[masks[index] > 0] = index + 1
    return image, labels

def plot_images_masks(image_ids):
    plt.close('all')
    fig, ax = plt.subplots(nrows=8,ncols=4, figsize=(50,50))
    for ax_index, image_id in enumerate(image_ids):
        image, labels = read_image_labels(image_id)
        img_row, img_col, mask_row, mask_col = int(ax_index/4)*2, ax_index%4, int(ax_index/4)*2 + 1, ax_index%4
        ax[img_row][img_col].imshow(image)
        ax[mask_row][mask_col].imshow(labels)

image_ids = check_output(["ls", "datasciencebowl2018/stage1_training/"]).decode("utf8").split()
print("Total Images in Training set: {}".format(len(image_ids)))
random_image_ids = random.sample(image_ids, 16)
print("Randomly Selected Images: {}, their IDs: {}".format(len(random_image_ids), random_image_ids))
plot_images_masks(random_image_ids)

"""I noticed some of the edge masks were just lines so I wanted to exclude these from my dataset. I used the following script to flag all masks that are 1 px wide (or empty). There turns out to be about 19 masks in the training set that are flagged."""

!rm datasciencebowl2018/stage1_training/.DS_Store/masks
from skimage.io import imread
for image in os.listdir(TRAIN_PATH):
    try: 
      mask_list = os.listdir("%s%s/masks" % (TRAIN_PATH, image))
      for mask in mask_list:
        try:
            full_path = "%s%s/masks/%s" % (TRAIN_PATH, image, mask)
            inp_mask = imread(full_path)
            if (np.count_nonzero(inp_mask) != 0):
                x_mask, y_mask = np.nonzero(inp_mask)
                size_x = max(x_mask) - min(x_mask) + 1
                size_y = max(y_mask) - min(y_mask) + 1
                if size_x < 2 or size_y < 2: # Flag Mask
                    print(full_path)
            else:
                print("Empty mask: %s" % (full_path))
        except:
          pass
    except:
          pass

warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
ignore_masks = ["ee43930956917b35e8ea9950119904ee43eeaf297ae2d0999a96bce06465119b.png", 
                "976fdddb84f5e86cc06b746252d103836124a0b0fa01865652789ee3ae1ebec0.png", 
                "e512fabd19592b09562cfabb45b7c3bff574d1f6818b7b53b5fede10016dc8b2.png", 
                "b82e80e4f8190720f38ea3fab4a05f133fd862b592db9ffd73f630500c7f94fb.png", 
                "879eb8b1875444d0f9e42755b1007978f9c3706285e862c7c42bf4900d1a5c1f.png", 
                "4713d7309386224347ea05586644b2fad515c272463c1662236109d1755191d9.png", 
                "493e574250a73120c05755367a2d032940563fdad88451d3ac42703fa93e1f8e.png", 
                "7ac528af7d96b1bae71a3b07d3f8de6dcde063c3dc2a84500fae46e46cd76bc6.png", 
                "777459648d2c4c18fe8df79e284fbec4decc5f3ffaf26930ec7d3d457b84ae62.png", 
                "9551f2dad01c71f81d5e2386a99bc963457338d0c79fda0e90e9226f50b5dada.png", 
                "069acba0cce8b22a267edd80e6c4303d9f8dd980bdcea0cf2569079b02cf6b41.png", 
                "4cff40e93297cd84240c4e05d861efc4c6c8ad6cab073968e75fea862639439e.png", 
                "2ec5a0547b47b663b91224a0b0b031ba26c6d81dd8c2271a0142ff50e7a3c90e.png", 
                "e707c768392b287baffc9307f2dc0d6a9993e40bcae8945caf0925bc789e4259.png", 
                "cd443eb126f389fb815a24b65035b306268bcfc3b4ad077c58110c5c1255805b.png", 
                "b9a160bc22b20d83a529f71b75f8ac11bed4f306c3d02d3d5496cefcda91666a.png", 
                "1f06b1d1ef191b4a0ecf28636d017d143114ac3e4760f0eb35f56af006d41a62.png", 
                "e969172b62b37ba15754478b69cefce1bf61534b46b4ac9e80e07a410815cfdc.png", 
                "0a0cb3d0373050e8f63302c2c1ab79c9a35249e98dda568418e79222eb9beb6f.png"]

def read_image_labels(image_id):
    # most of the content in this function is taken from 'Example Metric Implementation' kernel 
    # by 'William Cukierski'
    image_file = "datasciencebowl2018/stage1_training/{}/images/{}.png".format(image_id,image_id)
    mask_file = "datasciencebowl2018/stage1_training/{}/masks/*.png".format(image_id)
    image = skimage.io.imread(image_file)
    masks = skimage.io.imread_collection(mask_file).concatenate()    
    height, width, _ = image.shape
    num_masks = masks.shape[0]
    labels = np.zeros((height, width), np.uint16)
    for index in range(0, num_masks):
        labels[masks[index] > 0] = index + 1
    return image, labels

def data_aug(image,label,angel=30,resize_rate=0.9):
    flip = random.randint(0, 1)
    size = image.shape[0]
    rsize = random.randint(np.floor(resize_rate*size),size)
    w_s = random.randint(0,size - rsize)
    h_s = random.randint(0,size - rsize)
    sh = random.random()/2-0.25
    rotate_angel = random.random()/180*np.pi*angel
    # Create Afine transform
    afine_tf = transform.AffineTransform(shear=sh,rotation=rotate_angel)
    # Apply transform to image data
    image = transform.warp(image, inverse_map=afine_tf,mode='edge')
    label = transform.warp(label, inverse_map=afine_tf,mode='edge')
    # Randomly cropping image frame
    image = image[w_s:w_s+size,h_s:h_s+size,:]
    label = label[w_s:w_s+size,h_s:h_s+size]
    # Randomly flip frame
    if flip:
        image = image[:,::-1,:]
        label = label[:,::-1]
    return image, label

#warnings.filterwarnings('ignore', category=UserWarning, module='skimage')

# Setting seed for reproducability
seed = 42
random.seed = seed
np.random.seed = seed
smooth = 1.
epochs = 250

image_ids = check_output(["ls", "datasciencebowl2018/stage1_training/"]).decode("utf8").split()
image_id = image_ids[random.randint(0,len(image_ids))]
image, labels = read_image_labels(image_id)
plt.subplot(221)
plt.imshow(image)
plt.subplot(222)
plt.imshow(labels)

new_image, new_labels = data_aug(image,labels,angel=5,resize_rate=0.9)
plt.subplot(223)
plt.imshow(new_image)
plt.subplot(224)
plt.imshow(new_labels)



"""**Save the augmented data locally**"""

def make_data_augmentation(image_ids,split_num):
    for ax_index, image_id in tqdm(enumerate(image_ids),total=len(image_ids)):
        image,labels = read_image_labels(image_id)
        if not os.path.exists("datasciencebowl2018/stage1_training/{}/augs/".format(image_id)):
            os.makedirs("datasciencebowl2018/stage1_training/{}/augs/".format(image_id))
        if not os.path.exists("datasciencebowl2018/stage1_training/{}/augs_masks/".format(image_id)):
            os.makedirs("datasciencebowl2018/stage1_training/{}/augs_masks/".format(image_id))
            
        # also save the original image in augmented file 
        plt.imsave(fname="datasciencebowl2018/stage1_training/{}/augs/{}.png".format(image_id,image_id), arr = image)
        plt.imsave(fname="datasciencebowl2018/stage1_training/{}/augs_masks/{}.png".format(image_id,image_id),arr = labels)

        for i in range(split_num):
            new_image, new_labels = data_aug(image,labels,angel=5,resize_rate=0.9)
            aug_img_dir = "datasciencebowl2018/stage1_training/{}/augs/{}_{}.png".format(image_id,image_id,i)
            aug_mask_dir = "datasciencebowl2018/stage1_training/{}/augs_masks/{}_{}.png".format(image_id,image_id,i)
            plt.imsave(fname=aug_img_dir, arr = new_image)
            plt.imsave(fname=aug_mask_dir,arr = new_labels)

def clean_data_augmentation(image_ids):
    for ax_index, image_id in tqdm(enumerate(image_ids),total=len(image_ids)):
        if os.path.exists("datasciencebowl2018/stage1_training/{}/augs/".format(image_id)):
            shutil.rmtree("datasciencebowl2018/stage1_training/{}/augs/".format(image_id))
        if os.path.exists("datasciencebowl2018/stage1_training/{}/augs_masks/".format(image_id)):
            shutil.rmtree("datasciencebowl2018/stage1_training/{}/augs_masks/".format(image_id))


image_ids = check_output(["ls", "datasciencebowl2018/stage1_training/"]).decode("utf8").split()
split_num = 10
make_data_augmentation(image_ids,split_num)
clean_data_augmentation(image_ids)

# Get train and test IDs
train_ids = next(os.walk(TRAIN_PATH))[1]
test_ids = next(os.walk(TEST_PATH))[1]

# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python
def rle_encoding(x):
    dots = np.where(x.T.flatten() == 1)[0]
    run_lengths = []
    prev = -2
    for b in dots:
        if (b>prev+1): run_lengths.extend((b + 1, 0))
        run_lengths[-1] += 1
        prev = b
    return run_lengths

def prob_to_rles(x, cutoff=0.5):
    lab_img = label(x > cutoff)
    for i in range(1, lab_img.max() + 1):
        yield rle_encoding(lab_img == i)

# Iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage
def mask_to_rle(preds_test_upsampled):
    new_test_ids = []
    rles = []
    for n, id_ in enumerate(test_ids):
        rle = list(prob_to_rles(preds_test_upsampled[n]))
        rles.extend(rle)
        new_test_ids.extend([id_] * len(rle))
    return new_test_ids,rles

# Metric function
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

# Loss funtion
def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

from keras.layers import UpSampling2D
def get_CNN(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = Lambda(lambda x: x / 255) (inputs)
    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)
    c1 = Dropout(0.1) (c1)
    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
    p1 = MaxPooling2D((2, 2)) (c1)
    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
    c2 = Dropout(0.1) (c2)
    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
    p2 = MaxPooling2D((2, 2)) (c2)

    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)
    c3 = Dropout(0.2) (c3)
    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)
    p3 = MaxPooling2D((2, 2)) (c3)

    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)
    c4 = Dropout(0.2) (c4)
    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)
    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)
    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)
    c6 = UpSampling2D((2, 2))(c5)
    c7 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)
    c8 = UpSampling2D((2, 2))(c7)
    c9 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)
    c10 = UpSampling2D((2, 2))(c9)
    c11 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c10)
    c12 = UpSampling2D((2, 2))(c11)
    #c13 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c12)
    #c14 = UpSampling2D((2, 2))(c13)
 
    outputs = Conv2DTranspose(1, (1, 1), activation='sigmoid') (c12)
    
    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer='adam',loss='binary_crossentropy', metrics=[dice_coef])
    return model

get_CNN().summary()

#@title Default title text
!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# PyDrive reference:
# https://googledrive.github.io/PyDrive/docs/build/html/index.html

# Function read train images and mask return as nump array
def read_train_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):
    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
    print('Getting and resizing train images and masks ... ')
    sys.stdout.flush()
    if os.path.isfile("train_img.npy") and os.path.isfile("train_mask.npy"):
        print("Train file loaded from memory")
        X_train = np.load("train_img.npy")
        Y_train = np.load("train_mask.npy")
        return X_train,Y_train
    a = Progbar(len(train_ids))
    for n, id_ in enumerate(train_ids):
        path = TRAIN_PATH + id_
        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]
        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
        X_train[n] = img
        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
        for mask_file in next(os.walk(path + '/masks/'))[2]:
            mask_ = imread(path + '/masks/' + mask_file)
            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', 
                                        preserve_range=True), axis=-1)
            mask = np.maximum(mask, mask_)
        Y_train[n] = mask
        a.update(n)
    np.save("train_img",X_train)
    np.save("train_mask",Y_train)
    return X_train,Y_train
  # Function to read test images and return as numpy array
def read_test_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):
    X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
    sizes_test = []
    print('\nGetting and resizing test images ... ')
    sys.stdout.flush()
    if os.path.isfile("test_img.npy") and os.path.isfile("test_size.npy"):
        print("Test file loaded from memory")
        X_test = np.load("test_img.npy")
        sizes_test = np.load("test_size.npy")
        return X_test,sizes_test
    b = Progbar(len(test_ids))
    for n, id_ in enumerate(test_ids):
        path = TEST_PATH + id_
        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]
        sizes_test.append([img.shape[0], img.shape[1]])
        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
        X_test[n] = img
        b.update(n)
    np.save("test_img",X_test)
    np.save("test_size",sizes_test)
    return X_test,sizes_test

from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from skimage.morphology import label
#
!rm datasciencebowl2018/stage1_training/9bb6e39d5f4415bc7554842ee5d1280403a602f2ba56122b87f453a62d37c06e/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/b4de1e3eec159d8af1bd5447696f8996c31709edaf33e26ba9613816705847db/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/08151b19806eebd58e5acec7e138dbfbb1761f41a1ab9620466584ecc7d5fada/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/d4d88391bc399a3715440d4da9f8b7a973e010dc1edd9551df2e5a538685add5/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/54793624413c7d0e048173f7aeee85de3277f7e8d47c82e0a854fe43e879cd12/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/e49fc2b4f1f39d481a6525225ab3f688be5c87f56884456ad54c953315efae83/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/ac782d2cad7f515ce7276926209820e386248e3d619b2df81e22d5e3c160b7cb/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/a5fe0b7412dd152c41f7afc34ffdf276d4261b6942fa6d36803648e90f2cfc06/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/9facc652efe19f634639585d692a53dd6c2a8e2f0c9baebdfd85b9b41ec58851/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/1b44d22643830cd4f23c9deadb0bd499fb392fb2cd9526d81547d93077d983df/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/7f38885521586fc6011bef1314a9fb2aa1e4935bd581b2991e1d963395eab770/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/a1777737270c5f96c4523dff76e4097756f8f7d4c9d59bac079e31f9510deabd/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/02903040e19ddf92f452907644ad3822918f54af41dd85e5a3fe3e1b6d6f9339/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/f113626a04125d97b27f21b45a0ce9a686d73dee7b5dbc0725d49194ba0203bd/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/8d29c5a03e0560c8f9338e8eb7bccf47930149c8173f9ba4b9279fb87d86cf6d/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/777f7c4269279951ae05b56e806745e613297d411d048c0bce8964afd7d71a4b/masks/.DS_Store
!rm datasciencebowl2018/stage1_training/b3b1626f8ad156acb2963d1faa6a368f9378a266c3b90d9321087fdc5b3032b4/masks/.DS_Store
# get train_data
train_img,train_mask = read_train_data()

# get test_data
test_img,test_img_sizes = read_test_data()

from keras.callbacks import ModelCheckpoint 
checkpointer = ModelCheckpoint(filepath='nuclei.model.best.cnn', 
                               verbose=1, save_best_only=True)
# get u_net model
cnn = get_CNN()
# fit model on train_data
print("\nTraining...")
cnn.fit(train_img,train_mask,batch_size=16,epochs=epochs, 
          validation_split=0.1, callbacks=[checkpointer], 
          verbose=1, shuffle=True)

# load the weights that yielded the best validation accuracy
cnn.load_weights('nuclei.model.best.cnn')

uploaded = drive.CreateFile({'nuclei.model.best.cnn': 'nuclei.model.best.cnn'})
uploaded.SetContentFile('nuclei.model.best.cnn')
uploaded.Upload()
print('Uploaded file with ID {}'.format(uploaded.get('id')))

from google.colab import files

#files.download('nuclei.model.best.UNET')

print("Predicting")
# Predict on test data
test_mask = cnn.predict(test_img,verbose=1)

# Create list of upsampled test masks
test_mask_upsampled = []
for i in range(len(test_mask)):
    test_mask_upsampled.append(resize(np.squeeze(test_mask[i]),
                                       (test_img_sizes[i][0],test_img_sizes[i][1]), 
                                       mode='constant', preserve_range=True))

test_ids,rles = mask_to_rle(test_mask_upsampled)

# Create submission DataFrame
sub = pd.DataFrame()
sub['ImageId'] = test_ids
sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))

sub.to_csv('sub-dsbowl2018-cnn100.csv', index=False)

!ls

uploaded = drive.CreateFile({'sub-dsbowl2018-cnn100': 'sub-dsbowl2018-cnn100.csv'})
uploaded.SetContentFile('sub-dsbowl2018-cnn100.csv')
uploaded.Upload()
print('Uploaded file with ID {}'.format(uploaded.get('id')))

from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt
import numpy
def plot_loss(net):
  #print(net.history.history.values())
# summarize history for accuracy
  plt.plot(net.history.history['dice_coef'])
  plt.plot(net.history.history['val_dice_coef'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.show()
  plt.savefig('accuracy')
# summarize history for loss
  plt.plot(net.history.history['loss'])
  plt.plot(net.history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.show()
  plt.savefig('loss')

plot_loss(cnn)

import 
from google.colab import files

files.download('nuclei.model.best.UNET')

!kill -9 -1

